{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This is a base jupyter notebook for other solutions. It goes through the dataset A, and it finds the highest and the lowest energy production. It generates the solution with random floats inbetween the highest and the lowest production."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T09:54:56.674733992Z",
     "start_time": "2023-10-09T09:54:56.649991189Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-09T09:54:57.102787242Z",
     "start_time": "2023-10-09T09:54:57.069463516Z"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# load my custom function\n",
    "from solutions.few_regression_types import data_preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [],
   "source": [
    "# read datasets\n",
    "# for simplicity, I use X_train_estimated as test data for cross validation\n",
    "y = pd.read_parquet(\"../../dataset/A/train_targets.parquet\")\n",
    "X_train = pd.read_parquet(\"../../dataset/A/X_train_observed.parquet\")\n",
    "X_test = pd.read_parquet(\"../../dataset/A/X_train_estimated.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T09:54:58.826387335Z",
     "start_time": "2023-10-09T09:54:58.765666330Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [],
   "source": [
    "# edit data\n",
    "X_train, y_train = data_preprocess.preprocess_train_data(X_train, y, \"everything\")\n",
    "X_test, y_test = data_preprocess.preprocess_train_data(X_test, y, \"everything\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T09:55:00.289236826Z",
     "start_time": "2023-10-09T09:55:00.071887400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (29667, 47)\n",
      "X_test.shape = (4394, 47)\n",
      "y_train.shape = (29667, 1)\n",
      "y_test.shape = (4394, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train.shape = {X_train.shape}\")\n",
    "print(f\"X_test.shape = {X_test.shape}\")\n",
    "print(f\"y_train.shape = {y_train.shape}\")\n",
    "print(f\"y_test.shape = {y_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T09:55:01.124958262Z",
     "start_time": "2023-10-09T09:55:01.115539707Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Machine learning stuff"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "outputs": [
    {
     "data": {
      "text/plain": "621.0646291618334"
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decision tree\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred_tree = decision_tree.predict(X_test)\n",
    "\n",
    "mae_tree = np.mean(np.abs(np.array(y_test) - y_pred_tree))\n",
    "mae_tree"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T09:50:36.692367565Z",
     "start_time": "2023-10-09T09:50:35.831843467Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22433/3459638483.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  random_forest.fit(X_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": "601.50148550096"
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest\n",
    "random_forest = RandomForestRegressor(n_estimators=100)  # You can adjust the number of trees (n_estimators) as needed\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "\n",
    "mae_forest = np.mean(np.abs(np.array(y_test) - y_pred_forest))\n",
    "mae_forest"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T09:51:24.709181316Z",
     "start_time": "2023-10-09T09:50:36.677778329Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karel/.local/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "592.2928322998536"
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gradient boosting\n",
    "gradient_boosting = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1)  # You can adjust the number of trees (n_estimators) as needed\n",
    "gradient_boosting.fit(X_train, y_train)\n",
    "y_pred_grad = gradient_boosting.predict(X_test)\n",
    "\n",
    "mae_grad = np.mean(np.abs(np.array(y_test) - y_pred_grad))\n",
    "mae_grad"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T09:51:41.118262376Z",
     "start_time": "2023-10-09T09:51:24.684120388Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karel/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.684e+09, tolerance: 4.240e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": "599.946498024572"
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elastic net\n",
    "elastic_net = ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42)\n",
    "elastic_net.fit(X_train, y_train)\n",
    "y_pred_elast_net = elastic_net.predict(X_test)\n",
    "\n",
    "mae_elast_net = np.mean(np.abs(np.array(y_test) - y_pred_elast_net))\n",
    "mae_elast_net"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T09:51:43.773074078Z",
     "start_time": "2023-10-09T09:51:41.108032988Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karel/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "473.76274242555763"
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# support vector regression\n",
    "svr_model = SVR(kernel='rbf', C=1)\n",
    "svr_model.fit(X_train, y_train)\n",
    "y_pred_svr = svr_model.predict(X_test)\n",
    "\n",
    "mae_svr = np.mean(np.abs(np.array(y_test) - y_pred_svr))\n",
    "mae_svr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T09:53:08.822423259Z",
     "start_time": "2023-10-09T09:51:43.735638077Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karel/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1617: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 388104585.95711404\n",
      "Iteration 2, loss = 212355.63657117\n",
      "Iteration 3, loss = 196769.53189138\n",
      "Iteration 4, loss = 203915.13007081\n",
      "Iteration 5, loss = 206784.05595162\n",
      "Iteration 6, loss = 194935.93921548\n",
      "Iteration 7, loss = 201101.64384462\n",
      "Iteration 8, loss = 208473.30727063\n",
      "Iteration 9, loss = 519577.43169216\n",
      "Iteration 10, loss = 224599.43467255\n",
      "Iteration 11, loss = 256750.77851939\n",
      "Iteration 12, loss = 261413.44894045\n",
      "Iteration 13, loss = 237746.85662769\n",
      "Iteration 14, loss = 292756.00359130\n",
      "Iteration 15, loss = 317125.58913073\n",
      "Iteration 16, loss = 1819653.70409033\n",
      "Iteration 17, loss = 832021.81594735\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": "1106.8348379014724"
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neural network regression\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(512, 512), activation='relu', verbose=True, learning_rate=\"adaptive\")\n",
    "nn_model.fit(X_train, y_train)\n",
    "y_pred_nn = nn_model.predict(X_test)\n",
    "mae_nn = np.mean(np.abs(np.array(y_test) - y_pred_nn))\n",
    "mae_nn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T11:23:47.837708322Z",
     "start_time": "2023-10-09T11:22:46.278861943Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "outputs": [
    {
     "data": {
      "text/plain": "654.6119942364744"
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_nn[y_pred_nn < 0] = 0\n",
    "mae_nn = np.mean(np.abs(np.array(y_test) - y_pred_nn))\n",
    "mae_nn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T10:33:16.328324832Z",
     "start_time": "2023-10-09T10:33:16.163638820Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction on real test data\n",
    "\n",
    "\n",
    "SVR model came out with the lowest mean absolute error. So far we did only cross validation on the training data. SVR will be used on the real test data, on the datasets B and C and to generate the output csv file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karel/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_22433/1784412232.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[0;31m# learn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSVR\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkernel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'rbf'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mC\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1.0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m     \u001B[0mprediction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconcatenate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprediction\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0mprediction\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mprediction\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m0.\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    251\u001B[0m         \u001B[0mseed\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrnd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miinfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"i\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 252\u001B[0;31m         \u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msolver_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkernel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_seed\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mseed\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    253\u001B[0m         \u001B[0;31m# see comment on the other call to np.iinfo in this file\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    254\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\u001B[0m in \u001B[0;36m_dense_fit\u001B[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001B[0m\n\u001B[1;32m    329\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_status_\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    330\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_iter\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 331\u001B[0;31m         \u001B[0;34m)\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlibsvm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    332\u001B[0m             \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    333\u001B[0m             \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32msklearn/svm/_libsvm.pyx\u001B[0m in \u001B[0;36msklearn.svm._libsvm.fit\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# first dataset\n",
    "prediction = []\n",
    "\n",
    "for dataset in ['A', 'B', 'C']:\n",
    "    # read the data\n",
    "    print(f\"dataset {dataset}\")\n",
    "    X_train = pd.concat([\n",
    "        pd.read_parquet(\"../../dataset/A/X_train_observed.parquet\"),\n",
    "        pd.read_parquet(\"../../dataset/A/X_train_estimated.parquet\")\n",
    "    ], ignore_index=True)\n",
    "    y_train = pd.read_parquet(\"../../dataset/A/train_targets.parquet\")\n",
    "    X_test = pd.read_parquet(\"../../dataset/A/X_test_estimated.parquet\")\n",
    "    # preprocess the data\n",
    "    X_train, y_train = data_preprocess.preprocess_train_data(X_train, y_train, \"everything\")\n",
    "    X_test = data_preprocess.preprocess_test_data(X_test, \"everything\")\n",
    "    # learn \n",
    "    model = SVR(kernel='rbf', C=1.0)\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = np.concatenate((prediction, model.predict(X_test)))\n",
    "prediction[prediction < 0.] = 0.\n",
    "df = pd.DataFrame({'prediction': prediction})\n",
    "df.to_csv('svr.csv', index_label='id')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T09:54:49.488232935Z",
     "start_time": "2023-10-09T09:53:16.571684466Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
