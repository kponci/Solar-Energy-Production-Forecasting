{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This is a base jupyter notebook for other solutions. It goes through the dataset A, and it finds the highest and the lowest energy production. It generates the solution with random floats inbetween the highest and the lowest production."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T12:13:36.525766766Z",
     "start_time": "2023-10-02T12:13:36.421780711Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-02T12:13:36.526157817Z",
     "start_time": "2023-10-02T12:13:36.472546531Z"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "# read datasets\n",
    "# for simplicity, I use X_train_estimated as test data for cross validation\n",
    "y = pd.read_parquet(\"../../dataset/A/train_targets.parquet\")\n",
    "X_train = pd.read_parquet(\"../../dataset/A/X_train_observed.parquet\")\n",
    "X_test = pd.read_parquet(\"../../dataset/A/X_train_estimated.parquet\")\n",
    "\n",
    "# y is energy production every hour, but X is weather every 15 minutes\n",
    "X_train = X_train[X_train.index % 4 == 0]\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test = X_test[X_test.index % 4 == 0]\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# split y to train and test set\n",
    "n_train_rows = X_train.shape[0]\n",
    "n_test_rows = X_test.shape[0]\n",
    "y_train = y.iloc[:n_train_rows]\n",
    "y_test = y.iloc[-n_test_rows:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T12:13:36.558359086Z",
     "start_time": "2023-10-02T12:13:36.472877025Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (29668, 46)\n",
      "X_test.shape = (4394, 47)\n",
      "y_train.shape = (29668, 2)\n",
      "y_test.shape = (4394, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train.shape = {X_train.shape}\")\n",
    "print(f\"X_test.shape = {X_test.shape}\")\n",
    "print(f\"y_train.shape = {y_train.shape}\")\n",
    "print(f\"y_test.shape = {y_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T12:13:36.639586604Z",
     "start_time": "2023-10-02T12:13:36.532456093Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36604/4018083949.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_train.drop(\"time\", axis=1, inplace=True)\n",
      "/tmp/ipykernel_36604/4018083949.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_test.drop(\"time\", axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# edit data\n",
    "\n",
    "# remove date_calc column, because it is useless for energy production forecasting\n",
    "X_test.drop(\"date_calc\", axis=1, inplace=True)\n",
    "\n",
    "# remove date from y_train and y_test\n",
    "y_train.drop(\"time\", axis=1, inplace=True)\n",
    "y_test.drop(\"time\", axis=1, inplace=True)\n",
    "\n",
    "# split \"date_forecast\" feature into \"day of the year\" and \"time of the day\" in X_train\n",
    "X_train['day_of_year'] = X_train['date_forecast'].apply(lambda x: x.dayofyear)\n",
    "X_train['hour_of_day'] = X_train['date_forecast'].apply(lambda x: x.hour)\n",
    "X_train.drop('date_forecast', axis=1, inplace=True)\n",
    "\n",
    "# split \"date_forecast\" feature into \"day of the year\" and \"time of the day\" in X_test\n",
    "X_test['day_of_year'] = X_test['date_forecast'].apply(lambda x: x.dayofyear)\n",
    "X_test['hour_of_day'] = X_test['date_forecast'].apply(lambda x: x.hour)\n",
    "X_test.drop('date_forecast', axis=1, inplace=True)\n",
    "\n",
    "# there are NaNs in X_train and X_test (feature \"snow_density\"), replace them for zeros\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T12:13:36.814880922Z",
     "start_time": "2023-10-02T12:13:36.573717547Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Machine learning stuff"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "617.9890257921948"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decision tree\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred_tree = decision_tree.predict(X_test)\n",
    "\n",
    "mae_tree = np.mean(np.abs(np.array(y_test) - y_pred_tree))\n",
    "mae_tree"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T12:13:38.198802159Z",
     "start_time": "2023-10-02T12:13:36.799434129Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36604/3459638483.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  random_forest.fit(X_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": "599.8973885900494"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest\n",
    "random_forest = RandomForestRegressor(n_estimators=100)  # You can adjust the number of trees (n_estimators) as needed\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "\n",
    "mae_forest = np.mean(np.abs(np.array(y_test) - y_pred_forest))\n",
    "mae_forest"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T12:14:28.983824997Z",
     "start_time": "2023-10-02T12:13:38.190694044Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karel/.local/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "591.932941522667"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gradient boosting\n",
    "gradient_boosting = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1)  # You can adjust the number of trees (n_estimators) as needed\n",
    "gradient_boosting.fit(X_train, y_train)\n",
    "y_pred_grad = gradient_boosting.predict(X_test)\n",
    "\n",
    "mae_grad = np.mean(np.abs(np.array(y_test) - y_pred_grad))\n",
    "mae_grad"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T12:14:45.254024234Z",
     "start_time": "2023-10-02T12:14:28.984059518Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karel/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.684e+09, tolerance: 4.240e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": "599.6075209008663"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elastic net\n",
    "elastic_net = ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42)\n",
    "elastic_net.fit(X_train, y_train)\n",
    "y_pred_elast_net = elastic_net.predict(X_test)\n",
    "\n",
    "mae_elast_net = np.mean(np.abs(np.array(y_test) - y_pred_elast_net))\n",
    "mae_elast_net"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T12:14:48.490374669Z",
     "start_time": "2023-10-02T12:14:45.229708887Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karel/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "473.3314940446853"
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# support vector regression\n",
    "svr_model = SVR(kernel='rbf', C=1.0)\n",
    "svr_model.fit(X_train, y_train)\n",
    "y_pred_svr = svr_model.predict(X_test)\n",
    "\n",
    "mae_svr = np.mean(np.abs(np.array(y_test) - y_pred_svr))\n",
    "mae_svr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T12:16:07.037432943Z",
     "start_time": "2023-10-02T12:14:48.496620098Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVR model came out with the lowest mean absolute error. So far we did only cross validation on the training data. SVR will be used on the real test data, on the datasets B and C and to generate the output csv file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "            date_calc       date_forecast  absolute_humidity_2m:gm3  \\\n0 2023-04-30 07:00:04 2023-05-01 00:00:00                       4.4   \n1 2023-04-30 07:00:04 2023-05-01 00:15:00                       4.3   \n2 2023-04-30 07:00:04 2023-05-01 00:30:00                       4.3   \n3 2023-04-30 07:00:04 2023-05-01 00:45:00                       4.3   \n4 2023-04-30 07:00:04 2023-05-01 01:00:00                       4.3   \n\n   air_density_2m:kgm3  ceiling_height_agl:m  clear_sky_energy_1h:J  \\\n0                1.286            912.700012                    0.0   \n1                1.287            912.700012                    0.0   \n2                1.287            912.700012                    0.0   \n3                1.287            912.700012                    0.0   \n4                1.287                   NaN                    0.0   \n\n   clear_sky_rad:W  cloud_base_agl:m  dew_or_rime:idx  dew_point_2m:K  ...  \\\n0              0.0       1041.199951              0.0      271.700012  ...   \n1              0.0       1054.800049              0.0      271.700012  ...   \n2              0.0       1068.300049              0.0      271.600006  ...   \n3              0.0       1081.900024              0.0      271.600006  ...   \n4              0.0       1095.400024              0.0      271.600006  ...   \n\n   sun_azimuth:d  sun_elevation:d  super_cooled_liquid_water:kgm2  \\\n0      10.520000          -11.185                             0.0   \n1      14.203000          -10.825                             0.0   \n2      17.868999          -10.360                             0.0   \n3      21.514000           -9.794                             0.0   \n4      25.135000           -9.128                             0.0   \n\n   t_1000hPa:K  total_cloud_cover:p  visibility:m  wind_speed_10m:ms  \\\n0   273.799988            80.699997  30210.699219                4.0   \n1   273.799988            77.000000  30003.599609                4.0   \n2   273.799988            73.099998  29797.099609                3.9   \n3   273.799988            69.000000  29618.599609                3.9   \n4   273.799988            64.500000  29507.500000                3.9   \n\n   wind_speed_u_10m:ms  wind_speed_v_10m:ms  wind_speed_w_1000hPa:ms  \n0                  2.2                  3.4                     -0.0  \n1                  2.1                  3.4                     -0.0  \n2                  2.1                  3.3                     -0.0  \n3                  2.0                  3.3                     -0.0  \n4                  2.0                  3.3                     -0.0  \n\n[5 rows x 47 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_calc</th>\n      <th>date_forecast</th>\n      <th>absolute_humidity_2m:gm3</th>\n      <th>air_density_2m:kgm3</th>\n      <th>ceiling_height_agl:m</th>\n      <th>clear_sky_energy_1h:J</th>\n      <th>clear_sky_rad:W</th>\n      <th>cloud_base_agl:m</th>\n      <th>dew_or_rime:idx</th>\n      <th>dew_point_2m:K</th>\n      <th>...</th>\n      <th>sun_azimuth:d</th>\n      <th>sun_elevation:d</th>\n      <th>super_cooled_liquid_water:kgm2</th>\n      <th>t_1000hPa:K</th>\n      <th>total_cloud_cover:p</th>\n      <th>visibility:m</th>\n      <th>wind_speed_10m:ms</th>\n      <th>wind_speed_u_10m:ms</th>\n      <th>wind_speed_v_10m:ms</th>\n      <th>wind_speed_w_1000hPa:ms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-04-30 07:00:04</td>\n      <td>2023-05-01 00:00:00</td>\n      <td>4.4</td>\n      <td>1.286</td>\n      <td>912.700012</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1041.199951</td>\n      <td>0.0</td>\n      <td>271.700012</td>\n      <td>...</td>\n      <td>10.520000</td>\n      <td>-11.185</td>\n      <td>0.0</td>\n      <td>273.799988</td>\n      <td>80.699997</td>\n      <td>30210.699219</td>\n      <td>4.0</td>\n      <td>2.2</td>\n      <td>3.4</td>\n      <td>-0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023-04-30 07:00:04</td>\n      <td>2023-05-01 00:15:00</td>\n      <td>4.3</td>\n      <td>1.287</td>\n      <td>912.700012</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1054.800049</td>\n      <td>0.0</td>\n      <td>271.700012</td>\n      <td>...</td>\n      <td>14.203000</td>\n      <td>-10.825</td>\n      <td>0.0</td>\n      <td>273.799988</td>\n      <td>77.000000</td>\n      <td>30003.599609</td>\n      <td>4.0</td>\n      <td>2.1</td>\n      <td>3.4</td>\n      <td>-0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023-04-30 07:00:04</td>\n      <td>2023-05-01 00:30:00</td>\n      <td>4.3</td>\n      <td>1.287</td>\n      <td>912.700012</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1068.300049</td>\n      <td>0.0</td>\n      <td>271.600006</td>\n      <td>...</td>\n      <td>17.868999</td>\n      <td>-10.360</td>\n      <td>0.0</td>\n      <td>273.799988</td>\n      <td>73.099998</td>\n      <td>29797.099609</td>\n      <td>3.9</td>\n      <td>2.1</td>\n      <td>3.3</td>\n      <td>-0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023-04-30 07:00:04</td>\n      <td>2023-05-01 00:45:00</td>\n      <td>4.3</td>\n      <td>1.287</td>\n      <td>912.700012</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1081.900024</td>\n      <td>0.0</td>\n      <td>271.600006</td>\n      <td>...</td>\n      <td>21.514000</td>\n      <td>-9.794</td>\n      <td>0.0</td>\n      <td>273.799988</td>\n      <td>69.000000</td>\n      <td>29618.599609</td>\n      <td>3.9</td>\n      <td>2.0</td>\n      <td>3.3</td>\n      <td>-0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2023-04-30 07:00:04</td>\n      <td>2023-05-01 01:00:00</td>\n      <td>4.3</td>\n      <td>1.287</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1095.400024</td>\n      <td>0.0</td>\n      <td>271.600006</td>\n      <td>...</td>\n      <td>25.135000</td>\n      <td>-9.128</td>\n      <td>0.0</td>\n      <td>273.799988</td>\n      <td>64.500000</td>\n      <td>29507.500000</td>\n      <td>3.9</td>\n      <td>2.0</td>\n      <td>3.3</td>\n      <td>-0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 47 columns</p>\n</div>"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first dataset\n",
    "X_test = pd.read_parquet(\"../../dataset/A/X_test_estimated.parquet\")\n",
    "X_test.head()\n",
    "# TODO: sorry, not finished\n",
    "# TODO: join data X_train_observed, X_train_estimated and train SVR on that, predict on X_test_estimated.\n",
    "# TODO: do the same thing on the datasets B and C\n",
    "# TODO: put it the results to results.csv and upload on kaggle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T12:36:07.748711570Z",
     "start_time": "2023-10-02T12:36:07.680529562Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
