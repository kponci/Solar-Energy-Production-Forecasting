{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook, few regression types are tried using sklearn. They are trained on dataset X_train_observed and then crossvalidated on X_train_estimated (there is no particular reason behind dividing the dataset to training and testing part like this, I just decided it would be easiest way). \n",
    "\n",
    "This crossvalidation is tried just on dataset A. Then the solution with the lowest mean absolute error (mae) is chosen and used for the other datasets.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T05:28:14.052302930Z",
     "start_time": "2023-10-10T05:28:14.008635872Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-10T05:28:15.307340894Z",
     "start_time": "2023-10-10T05:28:14.567882924Z"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# load my custom functions\n",
    "from solutions.few_regression_types import data_preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# read dataset A\n",
    "# for simplicity, I use X_train_estimated as test data for cross validation\n",
    "y = pd.read_parquet(\"../../dataset/A/train_targets.parquet\")\n",
    "X_train = pd.read_parquet(\"../../dataset/A/X_train_observed.parquet\")\n",
    "X_test = pd.read_parquet(\"../../dataset/A/X_train_estimated.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T05:28:15.374967127Z",
     "start_time": "2023-10-10T05:28:15.305059896Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# edit data\n",
    "X_train, y_train = data_preprocess.preprocess_train_data(X_train, y, \"everything\")\n",
    "X_test, y_test = data_preprocess.preprocess_train_data(X_test, y, \"everything\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T05:07:36.838666874Z",
     "start_time": "2023-10-10T05:07:36.284106209Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (29667, 47)\n",
      "X_test.shape = (4394, 47)\n",
      "y_train.shape = (29667, 1)\n",
      "y_test.shape = (4394, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train.shape = {X_train.shape}\")\n",
    "print(f\"X_test.shape = {X_test.shape}\")\n",
    "print(f\"y_train.shape = {y_train.shape}\")\n",
    "print(f\"y_test.shape = {y_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T05:07:36.860814491Z",
     "start_time": "2023-10-10T05:07:36.617097333Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Machine learning methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "616.575890061115"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decision tree\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred_tree = decision_tree.predict(X_test)\n",
    "\n",
    "mae_tree = np.mean(np.abs(np.array(y_test) - y_pred_tree))\n",
    "mae_tree    # mae means mean absolute error, mae_tree = 616.575890061115"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T05:07:38.029789376Z",
     "start_time": "2023-10-10T05:07:36.627646761Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "599.9553060312836"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest\n",
    "random_forest = RandomForestRegressor(n_estimators=100)\n",
    "random_forest.fit(X_train, y_train.values.ravel()) # ravel part is because of scikit's data conversion warning, it does not have to be there\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "\n",
    "mae_forest = np.mean(np.abs(np.array(y_test) - y_pred_forest))\n",
    "mae_forest  # 599.9553060312836"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T05:08:43.351614721Z",
     "start_time": "2023-10-10T05:07:38.022561362Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "592.2928322998536"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gradient boosting\n",
    "gradient_boosting = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1) \n",
    "gradient_boosting.fit(X_train, y_train.values.ravel())\n",
    "y_pred_grad = gradient_boosting.predict(X_test)\n",
    "\n",
    "mae_grad = np.mean(np.abs(np.array(y_test) - y_pred_grad))\n",
    "mae_grad    # 592.2928322998536"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T05:09:00.460070793Z",
     "start_time": "2023-10-10T05:08:43.291886470Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karel/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.684e+09, tolerance: 4.240e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": "599.946498024572"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elastic net\n",
    "elastic_net = ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42)\n",
    "elastic_net.fit(X_train, y_train.values.ravel())\n",
    "y_pred_elast_net = elastic_net.predict(X_test)\n",
    "\n",
    "mae_elast_net = np.mean(np.abs(np.array(y_test) - y_pred_elast_net))\n",
    "mae_elast_net   # 599.946498024572"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T05:09:04.735282781Z",
     "start_time": "2023-10-10T05:09:00.421149131Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM].......................\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 23992\n",
      "obj = -19923.080123, rho = -23.964617\n",
      "nSV = 29662, nBSV = 29662\n"
     ]
    },
    {
     "data": {
      "text/plain": "345.1870758178765"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# support vector regression\n",
    "svr_model = SVR(kernel='rbf', C=1.)\n",
    "svr_model.fit(X_train, y_train.values.ravel())\n",
    "y_pred_svr = svr_model.predict(X_test)\n",
    "\n",
    "mae_svr = np.mean(np.abs(np.array(y_test) - y_pred_svr))\n",
    "mae_svr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T05:10:55.779718796Z",
     "start_time": "2023-10-10T05:09:04.675976472Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345.1870758178765, 362.3174570223702, 397.974746466719, 437.0422504854231, 473.76274242555763, 497.00397971674676, 513.0037055004162, "
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning of SVR\n",
    "# no need to run this section, it takes too long; the results are approx.: \n",
    "# [345, 362, 397, 437, 473, 497, 513] \n",
    "# lower C gives us better results\n",
    "for C in [0.001, 0.03, 0.1, 0.3, 1, 3, 10]:\n",
    "    svr_model = SVR(kernel='rbf', C=C)\n",
    "    svr_model.fit(X_train, y_train.values.ravel())\n",
    "    y_pred_svr = svr_model.predict(X_test)\n",
    "\n",
    "    print(np.mean(np.abs(np.array(y_test) - y_pred_svr)), end=\", \")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T05:21:20.763820351Z",
     "start_time": "2023-10-10T05:10:55.789288673Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction on real test data\n",
    "\n",
    "\n",
    "SVR model came out with the lowest mean absolute error. So far we did only cross validation on the training data. SVR will be used on the real test data, on the datasets B and C and to generate the output csv file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset A\n",
      "dataset B\n",
      "dataset C\n"
     ]
    }
   ],
   "source": [
    "prediction = []\n",
    "\n",
    "for letter in ['A', 'B', 'C']:\n",
    "    # read the data\n",
    "    print(f\"dataset {letter}\")\n",
    "    X_train = pd.concat([\n",
    "        pd.read_parquet(f\"../../dataset/{letter}/X_train_observed.parquet\"),\n",
    "        pd.read_parquet(f\"../../dataset/{letter}/X_train_estimated.parquet\")\n",
    "    ], ignore_index=True)\n",
    "    y_train = pd.read_parquet(f\"../../dataset/{letter}/train_targets.parquet\")\n",
    "    X_test = pd.read_parquet(f\"../../dataset/{letter}/X_test_estimated.parquet\")\n",
    "    # preprocess the data\n",
    "    X_train, y_train = data_preprocess.preprocess_train_data(X_train, y_train, \"everything\")\n",
    "    X_test = data_preprocess.preprocess_test_data(X_test, \"everything\")\n",
    "    # learn \n",
    "    model = SVR(kernel='rbf', C=.001)\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    prediction = np.concatenate((prediction, model.predict(X_test)))\n",
    "prediction[prediction < 0.] = 0. # energy production can't be negative\n",
    "df = pd.DataFrame({'prediction': prediction})\n",
    "df.to_csv('svr.csv', index_label='id')\n",
    "print(\"done\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T05:46:01.145833814Z",
     "start_time": "2023-10-10T05:41:15.610533094Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
