{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Short note - group 159\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T15:28:16.543304Z",
     "start_time": "2023-11-06T15:28:16.497145400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h2o\n",
    "import sklearn\n",
    "import matplotlib \n",
    "\n",
    "from h2o.automl import H2OAutoML\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This code was run for our best score (159.03). If you run it on your machine, there might be some differences. We tried to run it for a few times and even with the same seed we could not get the same result. This might be a thing with the used models. We have noticed that they change every day. \n",
    "\n",
    "We have also noticed that any type of basic work with data - removing columns, NaNs etc. made the MAE even worse.\n",
    "\n",
    "In a long note we tried even using the first two best models as predictors but without it was better.\n",
    "\n",
    "One of the used model interpretation is generated by H2O itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T05:07:36.838666874Z",
     "start_time": "2023-10-10T05:07:36.284106209Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# H2O\n",
    "\n",
    "all_predictions = pd.DataFrame()\n",
    "# Init of H2O\n",
    "h2o.init(max_mem_size = \"16G\") # If u have more RAM change the parameter\n",
    "\n",
    "for letter in ['A', 'B', 'C']:\n",
    "    # Load data\n",
    "    print(f\"dataset {letter}\")\n",
    "    # Load data from Parquet files and concatenate them into a single DataFrame 'X'\n",
    "    X = pd.concat([\n",
    "        pd.read_parquet(f\"../../dataset/{letter}/X_train_observed.parquet\"),\n",
    "        pd.read_parquet(f\"../../dataset/{letter}/X_train_estimated.parquet\")\n",
    "    ], ignore_index=True)\n",
    "    y = pd.read_parquet(f\"../../dataset/{letter}/train_targets.parquet\")\n",
    "    \n",
    "    # Preprocess the data\n",
    "    \n",
    "    # Merge DataFrame 'X' and 'y' based on the common column \"date_forecast\"\n",
    "    X_y_bacon = X.merge(y, left_on = \"date_forecast\", right_on = \"time\")\n",
    "    \n",
    "    # Load test data and remove specified columns\n",
    "    X_test = pd.read_parquet(f\"../../dataset/{letter}/X_test_estimated.parquet\")\n",
    "    X_test = X_test.iloc[::4]\n",
    "    #X_test.drop(columns=columns_to_drop, inplace=True)\n",
    "    x_test = h2o.H2OFrame(X_test)\n",
    "\n",
    "    \n",
    "    # Split data into training and validation frames (80:20)\n",
    "    train,test = sklearn.model_selection.train_test_split(X_y_bacon, test_size = 0.20)\n",
    "\n",
    "    train_frame = h2o.H2OFrame(train)\n",
    "    test_frame = h2o.H2OFrame(test)\n",
    "    \n",
    "    x = train_frame.columns[:-1] \n",
    "    y = train_frame.columns[-1] \n",
    "    \n",
    "    # Create an AutoML model\n",
    "    aml = H2OAutoML(max_runtime_secs = 60,\n",
    "                    sort_metric = \"MAE\",\n",
    "                    stopping_metric = \"MAE\",\n",
    "                    seed = 7213712285) \n",
    "    aml.train(x = x, \n",
    "              y = y,\n",
    "              training_frame = train_frame,\n",
    "              validation_frame = test_frame)\n",
    "    \n",
    "    print(aml.leaderboard)\n",
    "    best_model = aml.get_best_model(criterion='MAE')\n",
    "    \n",
    "    # Make predictions on test data and make CSV file\n",
    "    prediction1 = best_model.predict(x_test)\n",
    "    predictions1_df = h2o.as_list(prediction1)\n",
    "    predictions1_df[predictions1_df < 0.] = 0.\n",
    "    \n",
    "    all_predictions = pd.concat([all_predictions, predictions1_df], ignore_index=True)\n",
    "    all_predictions.to_csv('AutoML_H2O.csv', index_label='id')\n",
    "    print(\"CSV file updated\")\n",
    "\n",
    "# Explain the best model on the validation frame for model interpretation\n",
    "best_model.explain(test_frame)\n",
    "\n",
    "# Shut down H2O\n",
    "h2o.shutdown()\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
